{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, dot\n",
    "import keras.backend as K\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uncurl\n",
    "from uncurl import max_variance_genes, run_state_estimation\n",
    "import umap\n",
    "from tsne import bh_sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('../data/10x_pooled_400.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2747)\n"
     ]
    }
   ],
   "source": [
    "dat = np.log10(1 + mat['data'].toarray().astype(np.float32))\n",
    "genes = uncurl.max_variance_genes(dat, nbins=5, frac=0.2)\n",
    "dat = dat[genes,:]\n",
    "dat_T = dat.transpose()\n",
    "(c,g) = dat_T.shape\n",
    "print dat_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimizeW(M,dat_T,k):\n",
    "    (c,g) = dat_T.shape\n",
    "\n",
    "    enc_dim1 = 250 \n",
    "    enc_dim2 = 50 \n",
    "    enc_dim3 = k\n",
    "\n",
    "    inp1 = Input(shape=(g,))\n",
    "\n",
    "    enc_1 = Dense(enc_dim1, activation='relu')(inp1)\n",
    "    enc_2 = Dense(enc_dim2, activation='relu')(enc_1)\n",
    "    enc_3 = Dense(enc_dim3, activation='relu')(enc_2)\n",
    "    z = Dense(g, trainable=False)(enc_3)\n",
    "\n",
    "\n",
    "    encoder1 = Model(inp1,enc_3)\n",
    "\n",
    "    model = Model(inp1, z)\n",
    "    model.layers[4].set_weights([M.T,np.zeros((g,))])\n",
    "\n",
    "    model.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "    model.fit(dat_T, dat_T,\n",
    "                epochs=25,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(dat_T, dat_T))\n",
    "\n",
    "    W = encoder1.predict(dat_T)\n",
    "    return(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimizeM(W,dat,k):\n",
    "    (g,c) = dat.shape\n",
    "\n",
    "    enc_dim1 = 100 \n",
    "    enc_dim2 = 50 \n",
    "    enc_dim3 = k\n",
    "\n",
    "    inp1 = Input(shape=(c,))\n",
    "\n",
    "    enc_1 = Dense(enc_dim1, activation='relu')(inp1)\n",
    "    enc_2 = Dense(enc_dim2, activation='relu')(enc_1)\n",
    "    enc_3 = Dense(enc_dim3, activation='relu')(enc_2)\n",
    "    z = Dense(c, trainable=False)(enc_3)\n",
    "\n",
    "\n",
    "    encoder1 = Model(inp1,enc_3)\n",
    "\n",
    "    model = Model(inp1, z)\n",
    "    model.layers[4].set_weights([W,np.zeros((c,))])\n",
    "\n",
    "    model.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "    model.fit(dat, dat,\n",
    "                epochs=25,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(dat, dat))\n",
    "\n",
    "    M = encoder1.predict(dat)\n",
    "    return(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OuterLayer(dat,k,reps_unc = 2, reps_net = 2):\n",
    "    print('Optimizing UNCURL')\n",
    "    M_init, W_init, _ = run_state_estimation(dat, clusters=k, dist='Gaussian', reps = reps_unc)\n",
    "    print('Optimizing UNCURL-net')\n",
    "    \n",
    "    M = M_init + 0.0 \n",
    "    W = W_init + 0.0 \n",
    "    \n",
    "    for i in range(reps_net):\n",
    "        \n",
    "        print(\"Optimizing W iter\" + str(i))\n",
    "        W = OptimizeW(M,dat.T,k)\n",
    "        W = W.T\n",
    "        print(\"Optimizing M iter\" + str(i))\n",
    "        M = OptimizeM(W,dat,k)\n",
    "        \n",
    "        \n",
    "    return((M_init,W_init,M,W))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing UNCURL\n",
      "Optimizing UNCURL-net\n",
      "Optimizing W iter0\n",
      "Train on 400 samples, validate on 400 samples\n",
      "Epoch 1/25\n",
      "400/400 [==============================] - 83s 208ms/step - loss: 0.0246 - val_loss: 0.0169\n",
      "Epoch 2/25\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.0172 - val_loss: 0.0166\n",
      "Epoch 3/25\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.0163 - val_loss: 0.0140\n",
      "Epoch 4/25\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 5/25\n",
      "400/400 [==============================] - 0s 189us/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 6/25\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 7/25\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 8/25\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 9/25\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 10/25\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 11/25\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 12/25\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 13/25\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 14/25\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 15/25\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 16/25\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 17/25\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 18/25\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 19/25\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 20/25\n",
      "400/400 [==============================] - 0s 201us/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 21/25\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 22/25\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 23/25\n",
      "400/400 [==============================] - 0s 206us/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 24/25\n",
      "400/400 [==============================] - 0s 185us/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 25/25\n",
      "400/400 [==============================] - 0s 266us/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Optimizing M iter0\n",
      "Train on 2747 samples, validate on 2747 samples\n",
      "Epoch 1/25\n",
      "2747/2747 [==============================] - 75s 27ms/step - loss: 0.0156 - val_loss: 0.0133\n",
      "Epoch 2/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 3/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 4/25\n",
      "2747/2747 [==============================] - 0s 34us/step - loss: 0.0125 - val_loss: 0.0127\n",
      "Epoch 5/25\n",
      "2747/2747 [==============================] - 0s 33us/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 6/25\n",
      "2747/2747 [==============================] - 0s 33us/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 7/25\n",
      "2747/2747 [==============================] - 0s 33us/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 8/25\n",
      "2747/2747 [==============================] - 0s 32us/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 9/25\n",
      "2747/2747 [==============================] - 0s 45us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 10/25\n",
      "2747/2747 [==============================] - 0s 34us/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 11/25\n",
      "2747/2747 [==============================] - 0s 34us/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 12/25\n",
      "2747/2747 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 13/25\n",
      "2747/2747 [==============================] - 0s 40us/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 14/25\n",
      "2747/2747 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 15/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 16/25\n",
      "2747/2747 [==============================] - 0s 34us/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 17/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 18/25\n",
      "2747/2747 [==============================] - 0s 40us/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 19/25\n",
      "2747/2747 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 20/25\n",
      "2747/2747 [==============================] - 0s 40us/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 21/25\n",
      "2747/2747 [==============================] - 0s 41us/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 22/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 23/25\n",
      "2747/2747 [==============================] - 0s 34us/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 24/25\n",
      "2747/2747 [==============================] - 0s 34us/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 25/25\n",
      "2747/2747 [==============================] - 0s 40us/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Optimizing W iter1\n",
      "Train on 400 samples, validate on 400 samples\n",
      "Epoch 1/25\n",
      "400/400 [==============================] - 77s 193ms/step - loss: 0.0756 - val_loss: 0.0346\n",
      "Epoch 2/25\n",
      "400/400 [==============================] - 0s 262us/step - loss: 0.0345 - val_loss: 0.0344\n",
      "Epoch 3/25\n",
      "400/400 [==============================] - 0s 248us/step - loss: 0.0343 - val_loss: 0.0342\n",
      "Epoch 4/25\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.0342 - val_loss: 0.0342\n",
      "Epoch 5/25\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0341 - val_loss: 0.0341\n",
      "Epoch 6/25\n",
      "400/400 [==============================] - 0s 206us/step - loss: 0.0341 - val_loss: 0.0340\n",
      "Epoch 7/25\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.0340 - val_loss: 0.0340\n",
      "Epoch 8/25\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0339 - val_loss: 0.0338\n",
      "Epoch 9/25\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.0268 - val_loss: 0.0423\n",
      "Epoch 10/25\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.0271 - val_loss: 0.0141\n",
      "Epoch 11/25\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0138 - val_loss: 0.0136\n",
      "Epoch 12/25\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0136 - val_loss: 0.0141\n",
      "Epoch 13/25\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 14/25\n",
      "400/400 [==============================] - 0s 266us/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 15/25\n",
      "400/400 [==============================] - 0s 265us/step - loss: 0.0143 - val_loss: 0.0137\n",
      "Epoch 16/25\n",
      "400/400 [==============================] - 0s 270us/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 17/25\n",
      "400/400 [==============================] - 0s 238us/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 18/25\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 19/25\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 20/25\n",
      "400/400 [==============================] - 0s 201us/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 21/25\n",
      "400/400 [==============================] - 0s 201us/step - loss: 0.0139 - val_loss: 0.0135\n",
      "Epoch 22/25\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 23/25\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 24/25\n",
      "400/400 [==============================] - 0s 203us/step - loss: 0.0138 - val_loss: 0.0134\n",
      "Epoch 25/25\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0136 - val_loss: 0.0137\n",
      "Optimizing M iter1\n",
      "Train on 2747 samples, validate on 2747 samples\n",
      "Epoch 1/25\n",
      "2747/2747 [==============================] - 77s 28ms/step - loss: 0.0211 - val_loss: 0.0167\n",
      "Epoch 2/25\n",
      "2747/2747 [==============================] - 0s 50us/step - loss: 0.0142 - val_loss: 0.0125\n",
      "Epoch 3/25\n",
      "2747/2747 [==============================] - 0s 42us/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 4/25\n",
      "2747/2747 [==============================] - 0s 36us/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 5/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 6/25\n",
      "2747/2747 [==============================] - 0s 36us/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 7/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 8/25\n",
      "2747/2747 [==============================] - 0s 43us/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 9/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 10/25\n",
      "2747/2747 [==============================] - 0s 36us/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 11/25\n",
      "2747/2747 [==============================] - 0s 36us/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 12/25\n",
      "2747/2747 [==============================] - 0s 50us/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 13/25\n",
      "2747/2747 [==============================] - 0s 36us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 14/25\n",
      "2747/2747 [==============================] - 0s 40us/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 15/25\n",
      "2747/2747 [==============================] - 0s 38us/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 16/25\n",
      "2747/2747 [==============================] - 0s 40us/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 17/25\n",
      "2747/2747 [==============================] - 0s 36us/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 18/25\n",
      "2747/2747 [==============================] - 0s 36us/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 19/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 20/25\n",
      "2747/2747 [==============================] - 0s 37us/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 21/25\n",
      "2747/2747 [==============================] - 0s 38us/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 22/25\n",
      "2747/2747 [==============================] - 0s 34us/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 23/25\n",
      "2747/2747 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 24/25\n",
      "2747/2747 [==============================] - 0s 35us/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 25/25\n",
      "2747/2747 [==============================] - 0s 34us/step - loss: 0.0109 - val_loss: 0.0109\n"
     ]
    }
   ],
   "source": [
    "#run UNCURL for a few iterations\n",
    "k = 10\n",
    "(M_init,W_init,M,W) = OuterLayer(dat,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic UNCURL Purity =0.7525\n",
      "Deep UNCURL Purity =0.97\n"
     ]
    }
   ],
   "source": [
    "#Compare relative accuracy of approaches on clustering \n",
    "c_unc = W_init.argmax(0)\n",
    "c_net = W.argmax(0)\n",
    "print('Basic UNCURL Purity ='+str(uncurl.evaluation.purity(mat['labels'][0],c_unc)))\n",
    "print('Deep UNCURL Purity ='+str(uncurl.evaluation.purity(mat['labels'][0],c_net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
